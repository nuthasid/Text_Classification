{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training_Data:\n",
    "    \n",
    "    def __init__(self, data_file):\n",
    "        self.data_file = data_file\n",
    "        \n",
    "    def load_data(self):\n",
    "        \n",
    "        import os\n",
    "    \n",
    "        file_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'data', self.data_file))    \n",
    "        with open(file_path, 'rt', encoding='utf-8') as tf:\n",
    "            loaded_ad = tf.read().split('\\n')\n",
    "        job_ads = []\n",
    "        job_ads = [self.parse_data(item) for item in loaded_ad[:-1]]\n",
    "        self.raw_data = job_ads\n",
    "        self.classes = set([item['class'] for item in job_ads])\n",
    "    \n",
    "    def parse_data(self, input_line):\n",
    "        \n",
    "        cur_text = input_line.split('`')\n",
    "        ret_data = {}\n",
    "        ret_data['id'] = cur_text[1]\n",
    "        ret_data['company'] = cur_text[3]\n",
    "        ret_data['position'] = cur_text[5]\n",
    "        ret_data['url'] = cur_text[7]\n",
    "        ret_data['desc'] = cur_text[9]\n",
    "        ret_data['class'] = ''.join(cur_text[11:]).replace(',NA', '')\n",
    "    \n",
    "        return ret_data\n",
    "    \n",
    "    def create_training_set(self, labels):\n",
    "        \n",
    "        def remove_white_space(in_text):\n",
    "            \n",
    "            on_text = in_text[:].replace(u'\\xa0', ' ')\n",
    "            while on_text.find('  ') > -1:\n",
    "                on_text = on_text.replace('  ', ' ')\n",
    "                \n",
    "            return on_text\n",
    "        \n",
    "        self.label_dict = {}\n",
    "        for i, item in enumerate(labels):\n",
    "            self.label_dict[item] = i + 1\n",
    "        self.sample_desc = [remove_white_space(item['desc']) for item in self.raw_data]\n",
    "        self.sample_title = [remove_white_space(item['position']) for item in self.raw_data]\n",
    "        self.label = [self.label_dict[item['class']] if item['class'] in self.label_dict else 0 for item in self.raw_data]\n",
    "        self.label_names = [item['class'] if item['class'] in self.label_dict else 'Other' for item in self.raw_data]\n",
    "        \n",
    "    def balance_training_set(self, balance_class):\n",
    "    \n",
    "        import numpy as np\n",
    "        prop = np.mean([np.array(self.label) == self.label_dict[balance_class]])\n",
    "        \n",
    "        if prop < 0.5:\n",
    "            prop = prop / (1 - prop)\n",
    "            mask = [True if item == self.label_dict[balance_class] or np.random.rand() < prop else False for item in self.label]\n",
    "        else:\n",
    "            prop = (1 - prop) / prop\n",
    "            mask = [True if item != self.label_dict[balance_class] or np.random.rand() < prop else False for item in self.label]\n",
    "        sample_desc = []\n",
    "        sample_title = []\n",
    "        label = []\n",
    "        for i, item in enumerate(mask):\n",
    "            if item:\n",
    "                sample_desc.append(self.sample_desc[i])\n",
    "                sample_title.append(self.sample_title[i])\n",
    "                label.append(self.label[i])\n",
    "        self.sample_desc = sample_desc\n",
    "        self.sample_title = sample_title\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD = Training_Data('trainingset_20180406.csv')\n",
    "TD.load_data()\n",
    "TD.create_training_set(TD.classes)\n",
    "import pandas as pd\n",
    "ad_data = pd.Series(TD.label_names)\n",
    "#pd.value_counts(ad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD.create_training_set(['Other'])\n",
    "TD.balance_training_set('Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('..')\n",
    "from tokenizer import Tokenizer as my_tokenizer\n",
    "tkn1 = my_tokenizer(1)\n",
    "tkn2 = my_tokenizer(2)\n",
    "tkn3 = my_tokenizer(3)\n",
    "tkn4 = my_tokenizer(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(os.path.abspath(os.path.join(os.getcwd(), '..', 'dict', 'desc_vocab_small.txt'))  , 'rt', encoding='utf-8') as f_tv:\n",
    "    desc_vocab = f_tv.read().split('\\n')\n",
    "with open(os.path.abspath(os.path.join(os.getcwd(), '..', 'dict', 'title_vocab_small.txt'))  , 'rt', encoding='utf-8') as f_tv:\n",
    "    title_vocab = f_tv.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "desc_vectorizer = CountVectorizer(tokenizer=tkn2.tokenizer, vocabulary=desc_vocab)\n",
    "desc_vec = desc_vectorizer.fit_transform(TD.sample_desc)\n",
    "title_vectorizer = CountVectorizer(tokenizer=tkn4.tokenizer, vocabulary=title_vocab)\n",
    "title_vec = title_vectorizer.fit_transform(TD.sample_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(933, 19) (933, 39)\n",
      "(933, 58)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "print(desc_vec.shape, title_vec.shape)\n",
    "data_vec = hstack([title_vec, desc_vec])\n",
    "print(data_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "label_vec = np.array(TD.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70053476 0.73796791 0.68449198 0.72192513 0.67027027]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "clf = SVC()\n",
    "scores = cross_val_score(clf, data_vec, label_vec, cv=5, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Other       0.68      0.87      0.76       142\n",
      "       STEM       0.81      0.57      0.67       138\n",
      "\n",
      "avg / total       0.74      0.72      0.72       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "desc_train, desc_test, label_train, label_test = train_test_split(data_vec, label_vec, test_size=0.3)\n",
    "clf = clf.fit(desc_train, label_train)\n",
    "label_predict = clf.predict(desc_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_test, label_predict, target_names=['Other', 'STEM']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73535787 0.67979408 0.7234612 ]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Other       0.62      0.90      0.73       136\n",
      "       STEM       0.83      0.49      0.61       144\n",
      "\n",
      "avg / total       0.73      0.69      0.67       280\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Other       0.67      0.91      0.77       464\n",
      "       STEM       0.86      0.55      0.67       469\n",
      "\n",
      "avg / total       0.77      0.73      0.72       933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bclf = BernoulliNB()\n",
    "scores = cross_val_score(bclf, data_vec, label_vec, cv=3, scoring='f1_macro')\n",
    "print(scores)\n",
    "from sklearn.model_selection import train_test_split\n",
    "desc_train, desc_test, label_train, label_test = train_test_split(data_vec, label_vec, test_size=0.3)\n",
    "bclf = bclf.fit(desc_train, label_train)\n",
    "label_predict = bclf.predict(desc_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_test, label_predict, target_names=['Other', 'STEM']))\n",
    "in_bclf = BernoulliNB()\n",
    "in_bclf = in_bclf.fit(data_vec, label_vec)\n",
    "label_predict = bclf.predict(data_vec)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_vec, label_predict, target_names=['Other', 'STEM']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "para_bclf = in_bclf.get_params(True)\n",
    "print(para_bclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30985848 0.69014152]\n",
      " [0.11439851 0.88560149]\n",
      " [0.569949   0.430051  ]\n",
      " [0.569949   0.430051  ]\n",
      " [0.42458562 0.57541438]\n",
      " [0.11878726 0.88121274]\n",
      " [0.62879201 0.37120799]\n",
      " [0.569949   0.430051  ]\n",
      " [0.569949   0.430051  ]\n",
      " [0.9722248  0.0277752 ]]\n"
     ]
    }
   ],
   "source": [
    "prob_bclf = in_bclf.predict_proba(desc_test)\n",
    "print(prob_bclf[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6        0.63157895 0.72727273 0.66666667 0.61538462 0.81818182]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       other       0.67      0.75      0.71        24\n",
      "Clerks, etc.       0.73      0.64      0.68        25\n",
      "\n",
      " avg / total       0.70      0.69      0.69        49\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       other       0.95      1.00      0.97        86\n",
      "Clerks, etc.       1.00      0.93      0.97        76\n",
      "\n",
      " avg / total       0.97      0.97      0.97       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tclf = tree.DecisionTreeClassifier()\n",
    "scores = cross_val_score(tclf, data_vec, label_vec, cv=6, scoring='f1')\n",
    "print(scores)\n",
    "from sklearn.model_selection import train_test_split\n",
    "desc_train, desc_test, label_train, label_test = train_test_split(data_vec, label_vec, test_size=0.3)\n",
    "tclf = tclf.fit(desc_train, label_train)\n",
    "label_predict = tclf.predict(desc_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_test, label_predict, target_names=['other','Clerks, etc.']))\n",
    "in_tclf = tclf.fit(data_vec, label_vec)\n",
    "label_predict = tclf.predict(data_vec)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_vec, label_predict, target_names=['other','Clerks, etc.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "หัวหน้าส่วนงานบัญชี\n",
      "เพศ : ชาย , หญิง อายุ(ปี) : 30 ปีขึ้นไป ระดับการศึกษา : ปริญญาตรี - ปริญญาโท ประสบการณ์(ปี) : 5ปีขึ้นไป อื่นๆ : ไม่ระบุ คุณสมบัติเพิ่มเติม เคยปิดงบการเงิน มีความรู้ทางด้านภาษี และมาตรฐานบัญชี\n",
      "\n",
      "เจ้าหน้าที่ฝ่ายทรัพยากรมนุษย์\n",
      "หน้าที่ความรับผิดชอบ -ด้านสรรหา - รับผิดชอบงานสรรหาและสวัสดิการพนักงาน งานฝึกอบรม - ดูแลงานด้านกฏระเบียบข้อบังคับ ข้อกฏหมาย - จัดทำเอกสารการฝึกอบรม - ออกบูทรับสมัครงาน - ติดต่อประสานงานหน่วยงานที่เกี่ยวข้อง - ดูแลงานธุรการสำนักงานและงาน อื่นๆ ตามมอบหมาย เพศ : ชาย , หญิง อายุ(ปี) : 21 - 25 ระดับการศึกษา : ปริญญาตรี ประสบการณ์(ปี) : 1ปีขึ้นไป อื่นๆ : ยินดีรับนักศึกษาจบใหม่ คุณสมบัติเพิ่มเติม เพศ หญิง หรือ ชาย อายุไม่เกิน 25 ปี การศึกษาระดับปริญญาตรี สาขานิติศาสตร์ มีความกระตือรือร้น มีความคิดริเริ่ม มีแนวความคิดด้านงานบุคคลสมัยใหม่ บุคลิค มนุษย์สัมพันธ์ดี มีทักษะในการสื่อสารและประสานงาน สามารถทำงานภายใต้ภาวะกดดันได้ดี มีความรู้ภาษาอังกฤษระดับ ดี สามารถใช้โปรแกรมคอมพิวเตอร์ Word, Excel, Power Point และ อื่นๆ ได้เป็นอย่างดี สามารถใช้งาน Internet ได้เป็นอย่างดี\n",
      "\n",
      "พนักงานบัญชี\n",
      "งานเอกสาร คีย์ข้อมูลเข้าระบบและจัดเก็บเอกสาร เพศ หญิง อายุ 21-30 ปี ปวส. สาขาบัญชี เป็นคนละเอียด รอบคอบ ตั้งใจทำงาน ใช้โปรแกรมคอมพิวเตอร์พื้นฐานได้ดี\n",
      "\n",
      "เจ้าหน้าที่ฝ่ายวางแผนโครงการและการตลาด\n",
      "- วุฒิปริญญาตรี-โท สาขาการตลาด, บริหารธุรกิจ หรือสาขาที่เกี่ยวข้อง มีประสบการณ์ด้านการวางแผนโครงการและการตลาดอสังหาริมทรัพย์หรือที่เกี่ยวข้องอย่างน้อย 2 ปี ต้องการผู้ที่รักความก้าวหน้า กระตือรือร้น มีความคิดริเริ่มสร้างสรรค์ มีทักษะในการสื่อสาร สามารถใช้คอมพิวเตอร์ได้ดี อดทนต่องานหนัก ถ้ามีประสบการณ์ตรงจากธุรกิจอสังหาริมทรัพย์(บ้านจัดสรรและคอนโดมิเนียม) จะได้รับการพิจารณาเป็นพิเศษ\n",
      "\n",
      "ผู้จัดการสาขาเชียงใหม่\n",
      "บริหารจัดการงานทั่วไปของสาขา ได้แก่ งานการตลาด งานพิจารณารับประกันภัย งานสินไหมทดแทน งานบริหารทรัพยากรบุคคล งานบริการสำนักงาน และงานบัญชีการเงินสาขา ขยายฐานกลุ่มลูกค้าเป้าหมายในพื้นที่รับผิดชอบ รวมทั้งรักษาลูกค้าปัจจุบัน เช่น กลุ่มตัวแทนนายหน้า อู่ซ่อมแซมรถยนต์ สถาบันการเงิน หน่วยงานท้องถิ่น บริษัทห้างร้านต่างๆ เป็นตัวแทนรักษาภาพลักษณ์ของบริษัทฯ สร้างความสัมพันธ์ที่ดีกับหน่วยงานท้องถิ่น คู่ค้า และลูกค้า รวมทั้งให้ความรู้ความเข้าใจด้านการประกันภัยแก่ลูกค้าและกลุ่มเป้าหมาย จัดทำแผนการตลาดเพื่อรักษาฐานลูกค้าปัจจุบัน และแนวทางการขยายฐานลูกค้าใหม่ จัดกิจกรรมทางด้านการตลาด หรือกิจกรรมส่งเสริมความสัมพันธ์กับคู่ค้าและลูกค้า สำเร็จการศึกษาปริญญาตรี สาขาบริหารธุรกิจ หรือสาขาอื่นๆ ที่มีประสบการณ์ตรง มีประสบการณ์ทำงานด้านการบริหารทีมงาน หรือด้านประกันภัยอย่างน้อย 5 ปี มีภาวะผู้นำ บุคลิกภาพดี มีความมุ่งมั่น ทุ่มเท มีความรับผิดชอบสูง มีความคล่องตัว สามารถเดินทางทำงานพื้นที่จังหวัดใกล้เคียงได้ สามารถขับรถยนต์ได้ มีใบอนุญาตขับขี่ (บริษัทฯ จัดหารถยนต์ประจำสาขาให้ใช้งาน) มีภูมิลำเนาและชำนาญเส้นทางในพื้นที่ที่รับผิดชอบ จะป็นประโยชน์ต่อการทำงาน (บริษัทฯ จัดที่พักให้อยู่ฟรี) ไม่มีคุณสมบัติต้องห้ามของผู้ดำรงตำแหน่งผู้จัดการสาขา ซึ่งกำหนดโดย คปภ.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_all = bclf.predict(data_vec)\n",
    "false_neg = []\n",
    "for i, item in enumerate(predict_all):\n",
    "    if label_vec[i,] == 0 and predict_all[i,] != 0:\n",
    "        false_neg.append([TD.sample_title[i], TD.sample_desc[i]])\n",
    "for item in false_neg:\n",
    "    print(item[0] + '\\n' + item[1] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ธุรการ Collection - BTS หมอชิต (PP)\n",
      "\n",
      "เจ้าหน้าที่ฝ่ายขาย ในบริษัททัวร์\n",
      "\n",
      "Administrative Officer @iServe สาขา Central World\n",
      "\n",
      "เจ้าหน้าที่คีย์ข้อมูล\n",
      "\n",
      "Reservation Staff\n",
      "\n",
      "เลขา\n",
      "\n",
      "เจ้าหน้าที่ฝ่ายทรัพยากรมนุษย์ (HRD)\n",
      "\n",
      "ธุรการประสานงานโครงการ จ.ชลบุรี\n",
      "\n",
      "ธุรการประสานงานโครงการ กำแพงเพชร\n",
      "\n",
      "Account Payable & General Ledger Officer\n",
      "\n",
      "เจ้าหน้าที่ธุรการ (สำนักงานใหญ่)\n",
      "\n",
      "เจ้าหน้าที่ประสานงานลูกค้าภาษาอังกฤษเคยประสานงานในคลังสินค้าหรือประสานงานกับต่างประเทศ ประสบการณ์ 1 ปีขึ้นไป ทำงานแถวBTSแบริ่ง ติดต่อ 099-969-3522 คุณเอ\n",
      "\n",
      "พนักงานสโตร์\n",
      "\n",
      "เจ้าหน้าที่แผนกบัญชี\n",
      "\n",
      "เจ้าหน้าที่ฝ่ายพัฒนาบุคลากร\n",
      "\n",
      "Staff Event\n",
      "\n",
      "เจ้าหน้าที่แลกเปลี่ยนเงินตราต่างประเทศ : FXO (Foreign Exchange Officer) เป็นพนักงานประจำของธนาคารกสิกรไทย จำกัด(มหาชน) ประจำสนามบินสุวรรณภูมิ\n",
      "\n",
      "เจ้าหน้าที่จัดซื้อการตลาด (ภาษาอังกฤษ)\n",
      "\n",
      "จัดส่ง/ทำStock\n",
      "\n",
      "เจ้าหน้าที่ฝ่ายประชาสัมพันธ์\n",
      "\n",
      "Admin ประจำสาขา\n",
      "\n",
      "ธุรการ ช่าง (ประจำสำนักงานวิทยุ ลาดพร้าว)\n",
      "\n",
      "เจ้าหน้าที่บัญชี-การเงิน\n",
      "\n",
      "เจ้าหน้าที่ฝ่ายขาย Seafreight\n",
      "\n",
      "เจ้าหน้าที่บัญชี\n",
      "\n",
      "ธุรการสนาม**ด่วนจำนวนมาก\n",
      "\n",
      "Office Admin & Receptionist ปฏิบัติงานตึก Wave Place สัญญาจ้างปีต่อปี เงินเดือน 20k- AS\n",
      "\n",
      "เจ้าหน้าที่บัญชีเจ้าหนี้\n",
      "\n",
      "เจ้าหน้าที่รับแจ้งอุบัติเหตุ (กลางคืน)\n",
      "\n",
      "เจ้าหน้าที่ฝ่ายบุคคลธุรการ (ทำ Payroll)\n",
      "\n",
      "ธุรการ วุฒิปวสขึ้นไป - จตุจักร (PP)\n",
      "\n",
      "เจ้าหน้าที่ Checker\n",
      "\n",
      "ด่วนมาก! เจ้าหน้าที่บัญชีลูกหนี้ (เริ่มงานได้ภายใน 7 วัน มีผลต่อการพิจารณา)\n",
      "\n",
      "เจ้าหน้าที่ธุรการบัญชีสต็อก ด่วนมาก\n",
      "\n",
      "เจ้าหน้าที่ธุรการร้านอาหาร สาขาช่องนนทรี\n",
      "\n",
      "Administration Officer\n",
      "\n",
      "จนท.ประสานงานลูกค้าในประเทศ : Sales Coordinator Officer\n",
      "\n",
      "HR Officer ประจำโรงงานสนามชัยเขต จ.ฉะเชิงเทรา\n",
      "\n",
      "ธุรการประสานงานและพนักงานขาย\n",
      "\n",
      "จนท.ประจำส่วนงาน ของหอจดหมายเหตุฯ\n",
      "\n",
      "เจ้าหน้าที่ประชาสัมพันธ์\n",
      "\n",
      "เลขานุการ\n",
      "\n",
      "เจ้าหน้าที่ธุรการ ประชาสัมพันธ์\n",
      "\n",
      "พนักงานบัญชี\n",
      "\n",
      "เสมียน (ฝ่ายขาย)\n",
      "\n",
      "เจ้าหน้าที่ควบคุมเอกสาร (Document Control for ISO 9000)\n",
      "\n",
      "พนักงานนำเข้าข้อมูล\n",
      "\n",
      "พนักงานบัญชีและการเงิน\n",
      "\n",
      "Executive Secretary/Assistant Secretary\n",
      "\n",
      "เจ้าหน้าที่บัญชีหรือจัดซื้อ\n",
      "\n",
      "เจ้าหน้าที่ประสานงาน\n",
      "\n",
      "ประชาสัมพันธ์การตลาด\n",
      "\n",
      "เลขานุการบริษัท\n",
      "\n",
      "CR รับสมัครด่วน !\n",
      "\n",
      "ธุรการประสานงานขาย (สาขาดินแดง)\n",
      "\n",
      "ธุรการทั่วไป\n",
      "\n",
      "Sale Coordinate English Speaking or Japanese Speaking (ประจำสำนักงานที่กรุงเทพ)\n",
      "\n",
      "เจ้าหน้าที่ฝ่ายบุคคล\n",
      "\n",
      "การตลาดโครงการ\n",
      "\n",
      "Import-Export (Officer and Senior)\n",
      "\n",
      "เจ้าหน้าที่การเงิน รับสมัครด่วน !\n",
      "\n",
      "เจ้าหน้าควบคุมระบบและวิเคราะห์ข้อมูล\n",
      "\n",
      "พนักงานธุรการ\n",
      "\n",
      "DOCUMENT CONTROL\n",
      "\n",
      "ธุรการบัญชี\n",
      "\n",
      "พนักงานบัญชี และพนักงานฝ่ายบุคคล รับสมัครด่วน !\n",
      "\n",
      "ศูนย์บริการลูกค้าและพนักงาน (Agent) ฝ่ายลูกค้าสัมพันธ์ / Call Center\n",
      "\n",
      "เจ้าหน้าที่คำนวณราคาสินค้า\n",
      "\n",
      "ธุรการข้อมูล (ประจำ อ.หนองโดน) / (ประจำ อ.แก่งคอย) รับสมัครด่วน !\n",
      "\n",
      "เจ้าหน้าที่วางแผน/ธุรการฝ่ายผลิต รับสมัครด่วน !\n",
      "\n",
      "พนักงานบัญชี ปวส. - วุฒิปริญญาตรี\n",
      "\n",
      "Secretary to Managing Director / เลขานุการกรรมการผู้จัดการ 1 ตำแหน่ง\n",
      "\n",
      "ธุรการ-การเงิน\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(TD.label):\n",
    "    if item == 1:\n",
    "        print(TD.sample_title[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif as mic\n",
    "mutual_info_desc = mic(desc_vec, label_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_desc_info = []\n",
    "for token in desc_vectorizer.vocabulary_:\n",
    "    token_desc_info.append([token, mutual_info_desc[desc_vectorizer.vocabulary_[token]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('mutual_info_desc.txt', 'wt', encoding='utf-8', newline='') as of:\n",
    "    csv_write = csv.writer(of, delimiter=',', dialect='excel')\n",
    "    csv_write.writerows(token_desc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print([item for item in desc_vectorizer.vocabulary_][:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
