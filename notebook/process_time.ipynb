{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(step):\n",
    "\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    ## Construct Dataframe\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    class DataController():\n",
    "        dataMatrix = pd.DataFrame(columns=[\"title\",\"desc\",\"tag\"])\n",
    "\n",
    "        ## init will create dataMatrix\n",
    "        def __init__(self, pathToFile, step):\n",
    "            import os\n",
    "            import json\n",
    "            count = 0\n",
    "\n",
    "            print('Begin loading')\n",
    "            with open(pathToFile, 'r', encoding='utf-8') as fin:\n",
    "                for line in fin:\n",
    "                    ## for each line, add into dataMatrix, using [\"title\", \"desc\", \"tag\"] structure\n",
    "                    line_dict = json.loads(line, encoding='utf-8')\n",
    "                    self.dataMatrix = self.dataMatrix.append(line_dict, ignore_index=True)\n",
    "                    count+=1\n",
    "                    if count > step: break\n",
    "\n",
    "        def getTrainingSet(self, label_class):\n",
    "            ## classSet is set of data that has tag = label_class\n",
    "            targetSet = self.dataMatrix[self.dataMatrix['tag']==label_class]\n",
    "            restSet = self.dataMatrix[self.dataMatrix['tag']!=label_class]\n",
    "\n",
    "            if(targetSet.shape[0] < restSet.shape[0]):\n",
    "                # target has less population than the rest\n",
    "                trainingSet = pd.concat([targetSet, restSet.sample(n=targetSet.shape[0])])\n",
    "            else:\n",
    "                # target has more population than the rest\n",
    "                trainingSet = pd.concat([targetSet.sample(n=restSet.shape[0]), restSet])\n",
    "            # shuffle data using sample fraction = 1\n",
    "            trainingSet = trainingSet.sample(frac=1)\n",
    "            return trainingSet\n",
    "\n",
    "        def getData(self):\n",
    "            return self.dataMatrix\n",
    "\n",
    "    import os\n",
    "\n",
    "    file_name = \"masterDB_JPA Data - 20180406_flatten.json\"\n",
    "    #file_name = 'data20180620.json'\n",
    "    file_path = os.getcwd()+\"/../data/\"+file_name\n",
    "\n",
    "    data = DataController(file_path, step)\n",
    "    ## Create vectorized data\n",
    "    data = data.getData()\n",
    "    vec_Desc = data['desc'] \n",
    "    vec_Title = data['title']\n",
    "\n",
    "    ## create tokenizer\n",
    "    import sys\n",
    "    if not '..' in sys.path:\n",
    "        sys.path.append('..')\n",
    "    from tokenizer import Tokenizer\n",
    "    import deepcut as dp\n",
    "    def tokenizer(text):\n",
    "        return dp.tokenize(text)\n",
    "    #tkn1 = Tokenizer(1, dp.deepcut)\n",
    "    tkn2 = Tokenizer(2, tokenizer)\n",
    "    #tkn3 = Tokenizer(3, dp.deepcut)\n",
    "    tkn4 = Tokenizer(4, tokenizer)\n",
    "\n",
    "    ## open vocab file\n",
    "    #import os\n",
    "    #with open(os.path.abspath(os.path.join(os.getcwd(), '..', 'dict', 'desc_newdict_90p.txt'))  , 'rt', encoding='utf-8') as f_tv:\n",
    "    #    desc_vocab = f_tv.read().split('\\n')\n",
    "    #with open(os.path.abspath(os.path.join(os.getcwd(), '..', 'dict', 'title_newdict_90p.txt'))  , 'rt', encoding='utf-8') as f_tv:\n",
    "    #    title_vocab = f_tv.read().split('\\n')\n",
    "\n",
    "    ## create tfidf term-doc matrix\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    desc_vectorizer = TfidfVectorizer(tokenizer=tkn2.tokenizer, min_df=0.85)\n",
    "    desc_vectorizer.fit(vec_Desc)\n",
    "    #desc_vec = desc_vectorizer.fit_transform(training_Title)\n",
    "\n",
    "    title_vectorizer = TfidfVectorizer(tokenizer=tkn4.tokenizer, min_df=0.85)\n",
    "    title_vectorizer.fit(vec_Title)\n",
    "    #title_vec = title_vectorizer.fit_transform(training_Desc)\n",
    "    \n",
    "    return time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(timing(item)) for item in range(100, 1700, 100)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
